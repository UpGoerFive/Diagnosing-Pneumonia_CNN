{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sjVxwOMAfsmD"
   },
   "outputs": [],
   "source": [
    "def plot_model_metrics(hist, label=''):\n",
    "    '''\n",
    "    Generates plots on model metrics from the history.\n",
    "\n",
    "    Args:\n",
    "        hist (history object): Keras model history object\n",
    "        label (str): Name of model to be used for titles of graphs\n",
    "\n",
    "    Returns:\n",
    "        Model history record as a DataFrame\n",
    "\n",
    "    Example:\n",
    "        plot_model_metrics(history1, label='Base CNN Model')\n",
    "\n",
    "    '''\n",
    "\n",
    "#   Turning history into a DataFrame and saving to local drive\n",
    "    history_df = pd.DataFrame(hist.history)\n",
    "    name = label.replace(' ', '')\n",
    "    history_df.to_csv(f'history{name}.csv')\n",
    "\n",
    "\n",
    "#   Defining the training and validation variables\n",
    "    train_loss = history_df['loss']\n",
    "    train_accuracy = history_df['acc']\n",
    "    train_recall = history_df[history_df.columns[2]]\n",
    "    val_loss = history_df['val_loss']\n",
    "    val_accuracy = history_df['val_acc']\n",
    "    val_recall = history_df[history_df.columns[5]]\n",
    "\n",
    "#   Plotting the training vs validation accuracy\n",
    "    plt.plot(train_accuracy, label='Training Accuracy')\n",
    "    plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "    plt.title(f'Accuracy For {label}', fontdict={'fontsize':17})\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "#   Plotting the training vs validation loss\n",
    "    plt.figure()\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.title(f'Loss For {label}', fontdict={'fontsize':17})\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "#   Plotting the training vs validation recall\n",
    "    plt.figure()\n",
    "    plt.plot(train_recall, label='Training Recall')\n",
    "    plt.plot(val_recall, label='Validation Recall')\n",
    "    plt.title(f'Recall For {label}', fontdict={'fontsize':17})\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehWa5FgvfzrR"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def classification_report(model, y_true=y_test, Xtest=X_test, label=''):\n",
    "    '''\n",
    "    Creates a classification report for a model and saves model predictions\n",
    "    \n",
    "    Args:\n",
    "        model (classification model): Keras compatable model\n",
    "        y_true (array): Test set labels\n",
    "        Xtest (array): Test set images\n",
    "        label (str): Name of model to be used for titles\n",
    "    \n",
    "    Returns:\n",
    "        Classification report\n",
    "    \n",
    "    Example:\n",
    "        classification_report(model1, label='Base CNN Model')\n",
    "    '''\n",
    "    \n",
    "#   Generating predictions and saving to CSV file\n",
    "    y_hat = model.predict(Xtest).round()\n",
    "    name = label.replace(' ', '')\n",
    "    prediction_df = pd.DataFrame(y_hat)\n",
    "    prediction_df.to_csv(f'{name}Predictions.csv')\n",
    "\n",
    "#   Generating report and printing with nice formating\n",
    "    print('_____'*12)\n",
    "    print(f'CLASSIFICATION REPORT FOR: \\n\\t{label}')\n",
    "    print('_____'*12)     \n",
    "    report = metrics.classification_report(y_true, y_hat, \n",
    "                                        target_names=['normal', 'pneumonia'])\n",
    "    print(report)\n",
    "    print('_____'*12)\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98zyBTlYf2w6"
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(model, y_true=y_test, Xtest=X_test, label=''):\n",
    "    '''\n",
    "    Creates a confusion matrix plot with model predictions\n",
    "    \n",
    "    Args:\n",
    "        model (classification model): Keras compatable model\n",
    "        y_true (array): Test set labels\n",
    "        Xtest (array): Test set images\n",
    "        label (str): Name of model to be used for titles\n",
    "        \n",
    "    Returns:\n",
    "        Predictions from model\n",
    "        \n",
    "    Example:\n",
    "        confusion_matrix(model1, label='Base CNN Model')'''\n",
    "    \n",
    "#   Generate predictions\n",
    "    y_hat = model.predict(Xtest).round()\n",
    "     \n",
    "#   Plot the confusion matrix as a heatmap\n",
    "    ax = sns.heatmap(metrics.confusion_matrix(y_true, y_hat, \n",
    "                                         normalize='true'), \n",
    "                                         cmap='Greens', annot=True, \n",
    "                                        xticklabels=['normal', 'pneumonia'], \n",
    "                                        yticklabels=['normal', 'pneumonia'])\n",
    "    \n",
    "#   Setting labels and title\n",
    "    ax.set_xlabel('Predicted Label', fontdict={'fontsize':13})\n",
    "    ax.set_ylabel('True Label', fontdict={'fontsize':13})\n",
    "    ax.set_title(f'Confusion Matrix For {label}', fontdict={'fontsize':17})\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmMf_jvlf8Li"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, hist, y_true=y_test, Xtest=X_test, label=''):\n",
    "    '''\n",
    "    Saves model as a file and runs various evaluation functions\n",
    "    \n",
    "    Args:\n",
    "        model (classification model): Keras compatable model\n",
    "        hist (history object): Keras model history object\n",
    "        y_true (array): Test set labels\n",
    "        Xtest (array): Test set images\n",
    "        label (str): Name of model used for titles\n",
    "        \n",
    "    Returns:\n",
    "        Model\n",
    "    \n",
    "    Examples:\n",
    "        evaluate_model(model1, history1, label='Base CNN Model')\n",
    "    '''\n",
    "    \n",
    "#   Saving model as a file to local drive\n",
    "    name = label.replace(' ', '')\n",
    "    model.save(f'{name}.h5')\n",
    "    \n",
    "#   Running model evaluation functions\n",
    "    plot_model_metrics(hist, label=label)\n",
    "    classification_report(model, y_true=y_true, Xtest=Xtest, label=label)\n",
    "    confusion_matrix(model, y_true=y_true, Xtest=Xtest, label=label)\n",
    "    \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
