{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grace_starter model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1/B1F4V9mkoYiaJni9png",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grace-arina/Diagnosing-Pneumonia_CNN/blob/Grace_starter-models/Grace_starter_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycxzUFcIys7v",
        "outputId": "7ec27b73-18b8-4bd3-efb7-f9a247691db2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping, found downloaded files in \"./chest-xray-pneumonia\" (use force=True to force download)\n"
          ]
        }
      ],
      "source": [
        "import opendatasets as od\n",
        "od.download('https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
      ],
      "metadata": {
        "id": "RQxJp_dYBymh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data should be formatted into appropriately preprocessed floatingpoint\n",
        "tensors before being fed into the network. Currently, the data sits on a drive as\n",
        "JPEG files, so the steps for getting it into the network are roughly as follows:\n",
        "1.  Read the picture files.\n",
        "2.  Decode the JPEG content to RGB grids of pixels.\n",
        "3.  Convert these into floating-point tensors.\n",
        "4.  Rescale the pixel values (between 0 and 255) to the [0, 1] interval (as you know,\n",
        "neural networks prefer to deal with small input values)."
      ],
      "metadata": {
        "id": "k-Yq7jodGu2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an datagenerator object that will perform image augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=90,\n",
        "                                   width_shift_range=.2,\n",
        "                                   height_shift_range=.2,\n",
        "                                   shear_range=.2,\n",
        "                                   zoom_range=.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   brightness_range=[.5, 1.5])\n",
        "\n",
        "# Datagenerators for the test and validation set will only rescale the images\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "# Applying the datagenerator objects to the images in the folders\n",
        "\n",
        "train_set = train_datagen.flow_from_directory('./chest-xray-pneumonia/chest_xray/train/',\n",
        "                                                 target_size=(150, 150),\n",
        "                                                 batch_size=20,\n",
        "                                                 class_mode='binary',\n",
        "                                                 color_mode='grayscale')\n",
        "\n",
        "val_set = val_datagen.flow_from_directory('./chest-xray-pneumonia/chest_xray/val/',\n",
        "                                          target_size=(150, 150),\n",
        "                                          batch_size=20,\n",
        "                                          class_mode='binary',\n",
        "                                          color_mode='grayscale')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('./chest-xray-pneumonia/chest_xray/test/',\n",
        "                                            target_size=(150, 150),\n",
        "                                            batch_size=20,\n",
        "                                            class_mode='binary', \n",
        "                                            color_mode='grayscale')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_4GchlqACCx",
        "outputId": "90e7f108-49bf-4f23-ddda-16ad69332cc1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5216 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each split contains the same number of samples from each class: this is a balanced\n",
        "binary-classification problem, which means classification accuracy will be an\n",
        "appropriate measure of success."
      ],
      "metadata": {
        "id": "h_VEUblOFnl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "input_shape=(150, 150, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "vLoRzmpvFwlk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Letâ€™s look at how the dimensions of the feature maps change with every successive\n",
        "layer:"
      ],
      "metadata": {
        "id": "s6qZmx7HGF48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFDEJamJGIal",
        "outputId": "3d3b551e-3edf-4242-a775-9f53ff137654"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 148, 148, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 74, 74, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 17, 17, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 15, 15, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               3211776   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,452,545\n",
            "Trainable params: 3,452,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the compilation step, Iâ€™ll go with the RMSprop optimizer because I\n",
        "ended the network with a single sigmoid unit, Iâ€™ll use binary crossentropy as the\n",
        "loss"
      ],
      "metadata": {
        "id": "btH2tPDYGRHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "model.compile(loss='binary_crossentropy',\n",
        "optimizer='rmsprop',\n",
        "metrics=['acc'])"
      ],
      "metadata": {
        "id": "rqxlkp5yGW6Z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Letâ€™s fit the model to the data using the generator."
      ],
      "metadata": {
        "id": "gznyKuOEHZ7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_set,\n",
        "                    steps_per_epoch=100,\n",
        "                    epochs=30, \n",
        "                    validation_data=val_set,\n",
        "                    validation_steps=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r25Sw8w4Gcvd",
        "outputId": "038822de-494f-4f14-db94-3a7bb24397f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.5149 - acc: 0.7415\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 112s 1s/step - loss: 0.4798 - acc: 0.7735\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 111s 1s/step - loss: 0.4748 - acc: 0.7796\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.4246 - acc: 0.8025\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.4090 - acc: 0.8150\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 112s 1s/step - loss: 0.3974 - acc: 0.8150\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 112s 1s/step - loss: 0.3870 - acc: 0.8181\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.3551 - acc: 0.8385\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 107s 1s/step - loss: 0.3786 - acc: 0.8405\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 112s 1s/step - loss: 0.3718 - acc: 0.8360\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.3376 - acc: 0.8540\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.3290 - acc: 0.8597\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 107s 1s/step - loss: 0.3354 - acc: 0.8490\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 107s 1s/step - loss: 0.3245 - acc: 0.8505\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 107s 1s/step - loss: 0.3425 - acc: 0.8720\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 107s 1s/step - loss: 0.3159 - acc: 0.8720\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 106s 1s/step - loss: 0.3336 - acc: 0.8665\n",
            "Epoch 18/30\n",
            " 77/100 [======================>.......] - ETA: 24s - loss: 0.3368 - acc: 0.8643"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's good practice to save the model after training"
      ],
      "metadata": {
        "id": "CWcKiFmuNbHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('baseline_model.h5')"
      ],
      "metadata": {
        "id": "kA9rvCmkHxAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Letâ€™s plot the loss and accuracy of the model over the training and validation data\n",
        "during training"
      ],
      "metadata": {
        "id": "N6FBGRQtOEhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J_pKXpZeOH8h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}